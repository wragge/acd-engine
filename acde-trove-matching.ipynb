{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "269f718f-3a08-4958-8a66-12918e51a3ec",
   "metadata": {},
   "source": [
    "# Harvest Trove links using the SRU API\n",
    "\n",
    "You can query the People & Organisations data using the SRU (Search/Retrieve via URL) API. The easiest way to understand how to build SRU queries is to play around with the [online interface](http://www.nla.gov.au/apps/srw/search/peopleaustralia). More [information on the SRU protocol](https://www.loc.gov/standards/sru/) is available from the Library of Congress.\n",
    "\n",
    "Trove's people and organisation records are available in a number of XML formats, the richest and most complex of which is EAC-CPF. However, the XML records are not easy to work with, so to simplify further processing this notebook queries the SRU interface and then converts the XML results into JSON."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60c39de-30e9-4144-8af0-a8d1e68ac385",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import time\n",
    "from pathlib import Path\n",
    "import datetime\n",
    "\n",
    "import requests_cache\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import JSON, display\n",
    "from requests.adapters import HTTPAdapter\n",
    "from requests.packages.urllib3.util.retry import Retry\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "s = requests_cache.CachedSession()\n",
    "retries = Retry(total=5, backoff_factor=1, status_forcelist=[502, 503, 504])\n",
    "s.mount(\"https://\", HTTPAdapter(max_retries=retries))\n",
    "s.mount(\"http://\", HTTPAdapter(max_retries=retries))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a093b9-0709-4855-bdb6-79ec679f32c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Available SRU parameters\n",
    "\n",
    "params = {\n",
    "    #'query': 'rec.identifier=\"http://nla.gov.au/nla.party-641680\"', # Can specify a particular property, it not searches all (?) fields\n",
    "    \"query\": \"513fe28ad707ff6bcd001f56\",\n",
    "    \"version\": \"1.1\",\n",
    "    \"operation\": \"searchRetrieve\",\n",
    "    \"recordSchema\": \"urn:isbn:1-931666-33-4\",  # This specifies records in EAC-CPF format\n",
    "    \"maximumRecords\": 100,\n",
    "    \"startRecord\": 1,\n",
    "    \"resultSetTTL\": 300,\n",
    "    \"recordPacking\": \"xml\",\n",
    "    \"recordXPath\": \"\",\n",
    "    \"sortKeys\": \"\",\n",
    "}\n",
    "\n",
    "# SRU endpoint\n",
    "api_url = \"http://www.nla.gov.au/apps/srw/search/peopleaustralia\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c959ef-681d-4ac8-8b22-da03d25da5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_total_results(params):\n",
    "    params[\"maximumRecords\"] = 0\n",
    "    response = s.get(api_url, params=params)\n",
    "    soup = BeautifulSoup(response.content, \"xml\")\n",
    "    return int(soup.find(\"numberOfRecords\").string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c006708-34f0-48f9-af50-3cfe59075ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def soup_string(elem, prop):\n",
    "    \"\"\"\n",
    "    Saves on memory by not keeping BS navigable string\n",
    "    \"\"\"\n",
    "    if value := elem.find(prop):\n",
    "        string = str(value.string).strip()\n",
    "        if string == \"None\":\n",
    "            string = value.get_text()\n",
    "        return string\n",
    "\n",
    "\n",
    "def get_attr(elem, prop, attr):\n",
    "    if value := elem.find(prop):\n",
    "        return value.attrs.get(attr)\n",
    "\n",
    "\n",
    "def get_date(elem, prop):\n",
    "    try:\n",
    "        date = elem.find(prop)[\"standardDateTime\"]\n",
    "    except (KeyError):\n",
    "        try:\n",
    "            date = elem.find(prop)[\"standardDate\"]\n",
    "        except KeyError:\n",
    "            date = soup_string(elem, prop)\n",
    "    except TypeError:\n",
    "        date = None\n",
    "    return date\n",
    "\n",
    "\n",
    "def get_dates(history):\n",
    "    dates = {}\n",
    "    if history:\n",
    "        for event in history.find_all(\"maintenanceEvent\"):\n",
    "            event_type = soup_string(event, \"eventType\")\n",
    "            event_date = get_date(event, \"eventDateTime\")\n",
    "            if event_type == \"created\":\n",
    "                dates[\"date_created\"] = event_date\n",
    "            elif event_type == \"updated\":\n",
    "                dates[\"date_modified\"] = event_date\n",
    "    return dates\n",
    "\n",
    "\n",
    "def get_names(identity):\n",
    "    names = []\n",
    "    for name_entry in identity.find_all(\"nameEntry\"):\n",
    "        name = {}\n",
    "        for part in name_entry.find_all(\"part\"):\n",
    "            if part.has_attr(\"localType\"):\n",
    "                name_type = part[\"localType\"]\n",
    "            else:\n",
    "                name_type = \"name\"\n",
    "            try:\n",
    "                name[name_type].append(str(part.string))\n",
    "            except (KeyError, AttributeError):\n",
    "                name[name_type] = [str(part.string)]\n",
    "        if name_entry.find(\"authorizedForm\"):\n",
    "            name[\"authorized\"] = True\n",
    "        else:\n",
    "            name[\"authorized\"] = False\n",
    "        names.append(name)\n",
    "    return names\n",
    "\n",
    "\n",
    "def get_exist_dates(description):\n",
    "    exist_dates = {}\n",
    "    dates = description.find(\"existDates\")\n",
    "    if dates:\n",
    "        exist_dates[\"date_from\"] = get_date(dates, \"fromDate\")\n",
    "        exist_dates[\"date_to\"] = get_date(dates, \"toDate\")\n",
    "    return exist_dates\n",
    "\n",
    "\n",
    "def get_places(description):\n",
    "    places = []\n",
    "    places_elem = description.find(\"places\")\n",
    "    if places_elem:\n",
    "        for place_entry in places_elem.find_all(\"place\"):\n",
    "            place = {\n",
    "                \"place_type\": soup_string(place_entry, \"placeRole\"),\n",
    "                \"name\": soup_string(place_entry, \"placeEntry\"),\n",
    "                \"date_from\": get_date(place_entry, \"fromDate\"),\n",
    "                \"date_to\": get_date(place_entry, \"toDate\"),\n",
    "            }\n",
    "            places.append(place)\n",
    "    return places\n",
    "\n",
    "\n",
    "def get_events(description):\n",
    "    events = []\n",
    "    for event_list in description.find_all(\"chronList\"):\n",
    "        for event in event_list.find_all(\"chronItem\"):\n",
    "            events.append(\n",
    "                {\n",
    "                    \"name\": soup_string(event, \"event\"),\n",
    "                    \"date\": get_date(event, \"date\"),\n",
    "                    \"date_from\": get_date(event, \"fromDate\"),\n",
    "                    \"date_to\": get_date(event, \"toDate\"),\n",
    "                }\n",
    "            )\n",
    "    return events\n",
    "\n",
    "\n",
    "def get_occupations(description):\n",
    "    occupations = []\n",
    "    if occupation_list := description.find(\"occupations\"):\n",
    "        for occupation in occupation_list.find_all(\"occupation\"):\n",
    "            occupations.append(soup_string(occupation, \"term\"))\n",
    "    return occupations\n",
    "\n",
    "\n",
    "def get_related_entities(eac):\n",
    "    related = []\n",
    "    for relation in eac.find_all(\"cpfRelation\"):\n",
    "        # Can be resourceRelation or cpfRelation\n",
    "        if description := relation.find(\"descriptiveNote\"):\n",
    "            description = description.get_text().strip()\n",
    "        else:\n",
    "            description = None\n",
    "        related.append(\n",
    "            {\n",
    "                \"relation_type\": relation.attrs.get(\"cpfRelationType\"),\n",
    "                \"href\": relation.attrs.get(\"href\"),\n",
    "                \"name\": soup_string(relation, \"relationEntry\"),\n",
    "                \"entity_type\": get_attr(relation, \"relationEntry\", \"localType\"),\n",
    "                \"date_from\": get_date(relation, \"fromDate\"),\n",
    "                \"date_to\": get_date(relation, \"toDate\"),\n",
    "                \"description\": description,\n",
    "            }\n",
    "        )\n",
    "    return related\n",
    "\n",
    "\n",
    "def get_related_resources(eac):\n",
    "    related = []\n",
    "    for relation in eac.find_all(\"resourceRelation\"):\n",
    "        # Can be resourceRelation or cpfRelation\n",
    "        relation_type = relation.attrs.get(\"resourceRelationType\")\n",
    "        if relation.find(\"dc\"):\n",
    "            if description := relation.find_all(\"description\"):\n",
    "                description = \" \".join([d.get_text() for d in description])\n",
    "            related.append(\n",
    "                {\n",
    "                    \"relation_type\": relation_type,\n",
    "                    \"href\": soup_string(relation, \"identifier\"),\n",
    "                    \"name\": soup_string(relation, \"title\"),\n",
    "                    \"resource_type\": None,\n",
    "                    \"contributor\": soup_string(relation, \"contributor\"),\n",
    "                    \"date\": soup_string(relation, \"date\"),\n",
    "                    \"description\": description,\n",
    "                }\n",
    "            )\n",
    "        else:\n",
    "            if description := relation.find(\"abstract\"):\n",
    "                description = description.get_text()\n",
    "            related.append(\n",
    "                {\n",
    "                    \"relation_type\": relation_type,\n",
    "                    \"href\": relation.attrs.get(\"href\"),\n",
    "                    \"name\": soup_string(relation, \"relationEntry\"),\n",
    "                    \"resource_type\": get_attr(relation, \"relationEntry\", \"localType\"),\n",
    "                    \"contributor\": soup_string(relation, \"name\"),\n",
    "                    \"date\": soup_string(relation, \"date\"),\n",
    "                    \"description\": description,\n",
    "                }\n",
    "            )\n",
    "    return related\n",
    "\n",
    "\n",
    "def get_biog(description):\n",
    "    biog = []\n",
    "    for bio in description.find_all(\"biogHist\"):\n",
    "        for para in bio.find_all(\"p\"):\n",
    "            biog.append(str(para.string).strip())\n",
    "    return \" \".join(biog)\n",
    "\n",
    "\n",
    "def get_sources(eac):\n",
    "    sources = []\n",
    "    for source_eac in eac.find_all(\"eac-cpf\"):\n",
    "        source = process_eac(source_eac)\n",
    "        source[\"related_entities\"] = get_related_entities(source_eac)\n",
    "        source[\"related_resources\"] = get_related_resources(source_eac)\n",
    "        sources.append(source)\n",
    "    return sources\n",
    "\n",
    "\n",
    "def get_agency_details(agency_element):\n",
    "    agency = {\n",
    "        \"agency_id\": soup_string(agency_element, \"agencyCode\"),\n",
    "        \"agency_name\": soup_string(agency_element, \"agencyName\"),\n",
    "    }\n",
    "    return agency\n",
    "\n",
    "\n",
    "def get_eac_meta(eac):\n",
    "    meta = {\"record_id\": soup_string(eac, \"recordId\")}\n",
    "    control = eac.find(\"control\")\n",
    "    # agency\n",
    "    meta.update(get_agency_details(control.find(\"maintenanceAgency\")))\n",
    "    meta.update(get_dates(control.find(\"maintenanceHistory\")))\n",
    "    return meta\n",
    "\n",
    "\n",
    "def format_name(names, entity_type):\n",
    "    authorized = None\n",
    "    combined_names = []\n",
    "    for name in names:\n",
    "        if name[\"authorized\"] is True:\n",
    "            authorized = name\n",
    "            break\n",
    "    if not authorized:\n",
    "        try:\n",
    "            authorized = names[0]\n",
    "        except IndexError:\n",
    "            pass\n",
    "    if authorized:\n",
    "        for name_type in [\"forename\", \"surname\", \"name\", \"parent\"]:\n",
    "            combined_names += authorized.get(name_type, [])\n",
    "    return \" \".join(combined_names)\n",
    "\n",
    "\n",
    "def process_eac(eac):\n",
    "    record = get_eac_meta(eac)\n",
    "    identity = eac.find(\"identity\")\n",
    "    record[\"names\"] = get_names(identity)\n",
    "    record[\"entity_type\"] = soup_string(identity, \"entityType\")\n",
    "    record[\"entity_id\"] = soup_string(identity, \"entityId\")\n",
    "    record[\"name\"] = format_name(record[\"names\"], record[\"entity_type\"])\n",
    "    description = eac.find(\"description\")\n",
    "    if not description:\n",
    "        description = eac.find(\"cpfDescription\")\n",
    "    record[\"dates\"] = get_exist_dates(description)\n",
    "    record[\"places\"] = get_places(description)\n",
    "    record[\"occupations\"] = get_occupations(description)\n",
    "    record[\"abstract\"] = soup_string(description, \"abstract\")\n",
    "    record[\"description\"] = get_biog(description)\n",
    "    record[\"events\"] = get_events(description)\n",
    "    record[\"sources\"] = get_sources(eac)\n",
    "    return record\n",
    "\n",
    "\n",
    "def get_records(params):\n",
    "    records = []\n",
    "    response = s.get(api_url, params=params)\n",
    "    soup = BeautifulSoup(response.content, \"xml\")\n",
    "    for result in soup.find_all(\"record\"):\n",
    "        eac = result.find(\"eac-cpf\")\n",
    "        # get id info here\n",
    "        record = process_eac(eac)\n",
    "        record[\"trove_url\"] = f\"https://nla.gov.au/nla.party-{record['record_id']}\"\n",
    "        records.append(record)\n",
    "    return records\n",
    "\n",
    "\n",
    "def harvest_results(params):\n",
    "    records = []\n",
    "    total = get_total_results(params.copy())\n",
    "    start = 1\n",
    "    with tqdm(total=total) as pbar:\n",
    "        while start <= total:\n",
    "            params[\"start\"] = start\n",
    "            new_records = get_records(params)\n",
    "            records += new_records\n",
    "            start += 100\n",
    "            pbar.update(len(new_records))\n",
    "    return records"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb854390-4c30-4c16-82d3-ed9ab2a3632d",
   "metadata": {},
   "source": [
    "## Harvest Trove links from ACDEngine records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0b7c7a-0bd7-4800-a819-ea6ee7958a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trove_sources = {\"DAAO\": \"AU-NUN:DAAO\", \"AusStage\": \"AU-SAUS\"}\n",
    "\n",
    "\n",
    "def harvest_trove_links(acde_source):\n",
    "    with Path(\"ACDE_Merged_Normalized_202206031344.json\").open(\"r\") as json_file:\n",
    "        acde_json = json.load(json_file)\n",
    "    links = []\n",
    "    not_found = []\n",
    "    relations = []\n",
    "    resources = []\n",
    "    for record in tqdm(acde_json):\n",
    "        if record[\"data_source\"] == acde_source:\n",
    "            if acde_source == \"AusStage\":\n",
    "                ori_id = f\"ausstage:Contributor:{record['ori_id']}\"\n",
    "            else:\n",
    "                ori_id = record['ori_id']\n",
    "            params[\"query\"] = f\"rec.identifier='{ori_id}'\"\n",
    "            results = get_records(params.copy())\n",
    "            if len(results) > 1:\n",
    "                print(f\"Too many: {record['ori_id']}\")\n",
    "            elif len(results) == 0:\n",
    "                not_found.append(record[\"ori_id\"])\n",
    "            else:\n",
    "                link = results[0]\n",
    "                links.append(\n",
    "                    {\n",
    "                        \"acde_source\": acde_source,\n",
    "                        \"or_id\": record[\"ori_id\"],\n",
    "                        \"related_source\": \"Trove\",\n",
    "                        \"related_source_id\": link[\"record_id\"],\n",
    "                        \"related_source_url\": link[\"trove_url\"],\n",
    "                        \"related_source_name\": link[\"name\"]\n",
    "                    }\n",
    "                )\n",
    "                for source in link[\"sources\"]:\n",
    "                    if source[\"agency_id\"] != trove_sources[acde_source]:\n",
    "                        links.append(\n",
    "                            {\n",
    "                                \"acde_source\": acde_source,\n",
    "                                \"or_id\": record[\"ori_id\"],\n",
    "                                \"related_source\": source[\"agency_id\"],\n",
    "                                \"related_source_id\": source[\"record_id\"],\n",
    "                                \"related_source_url\": source[\"entity_id\"],\n",
    "                                \"related_source_name\": source[\"name\"]\n",
    "                            }\n",
    "                        )\n",
    "                        for resource in source[\"related_resources\"]:\n",
    "                            if resource[\"name\"] != \"Aboriginal and Torres Strait Islander Biographical Index (ABI) Entries\":\n",
    "                                resource_id = {\n",
    "                                    \"acde_source\": acde_source,\n",
    "                                    \"or_id\": record[\"ori_id\"],\n",
    "                                    \"related_source\": source[\"agency_id\"],\n",
    "                                    \"related_source_id\": source[\"record_id\"],\n",
    "                                    \"related_source_url\": source[\"entity_id\"],\n",
    "                                    \"related_source_name\": source[\"name\"]\n",
    "                                }\n",
    "                                # Merge dicts and append\n",
    "                                resources.append({**resource_id, **resource})\n",
    "                        for resource in source[\"related_entities\"]:\n",
    "                            resource_id = {\n",
    "                                \"acde_source\": acde_source,\n",
    "                                \"or_id\": record[\"ori_id\"],\n",
    "                                \"related_source\": source[\"agency_id\"],\n",
    "                                \"related_source_id\": source[\"record_id\"],\n",
    "                                \"related_source_url\": source[\"entity_id\"],\n",
    "                                \"related_source_name\": source[\"name\"]\n",
    "                            }\n",
    "                            # Merge dicts and append\n",
    "                            relations.append({**resource_id, **resource})\n",
    "            time.sleep(0.2)\n",
    "    with Path(f\"{acde_source.lower()}_trove_links_{datetime.datetime.now().strftime('%Y%m%d')}.json\").open(\"w\") as json_file:\n",
    "        json.dump(links, json_file)\n",
    "    with Path(f\"{acde_source.lower()}_trove_not_found_{datetime.datetime.now().strftime('%Y%m%d')}.json\").open(\"w\") as json_file:\n",
    "        json.dump(not_found, json_file)\n",
    "    with Path(f\"{acde_source.lower()}_trove_relations_{datetime.datetime.now().strftime('%Y%m%d')}.json\").open(\"w\") as json_file:\n",
    "        json.dump(relations, json_file)\n",
    "    with Path(f\"{acde_source.lower()}_trove_resources_{datetime.datetime.now().strftime('%Y%m%d')}.json\").open(\"w\") as json_file:\n",
    "        json.dump(resources, json_file)\n",
    "                                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c09ca4f-06bc-483f-a3b9-38d14f22fd31",
   "metadata": {
    "tags": [
     "nbval-skip"
    ]
   },
   "outputs": [],
   "source": [
    "for source in [\"DAAO\", \"AusStage\"]:\n",
    "    harvest_trove_links(source)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39510160-d29b-4e63-9c23-95a553603304",
   "metadata": {},
   "source": [
    "## Get urls for DAAO ids\n",
    "\n",
    "The DAAO ids in the ACDEngine dataset are hashes, but in Wikidata they're url paths, so we can't use the hash identifiers to match ACDEngine records with Wikidata. However, Trove includes both the has ids and the urls, so if DAAO records are in Trove we can get the url paths from the hashes and use them with Wikidata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d14a1d-6d46-437d-aa47-4002dfc15beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_daao_urls():\n",
    "    \"\"\"\n",
    "    Query Trove with DAAO hash identifiers and retrieve DAAO urls.\n",
    "    \"\"\"\n",
    "    with Path(\"ACDE_Merged_Normalized_202206031344.json\").open(\"r\") as json_file:\n",
    "        acde_json = json.load(json_file)\n",
    "    links = []\n",
    "    for record in tqdm(acde_json):\n",
    "        if record[\"data_source\"] == \"DAAO\":\n",
    "            params[\"query\"] = f\"rec.identifier='{record['ori_id']}'\"\n",
    "            results = get_records(params.copy())\n",
    "            if len(results) > 1:\n",
    "                print(f\"Too many: {record['ori_id']}\")\n",
    "            elif len(results) == 0:\n",
    "                pass\n",
    "            else:\n",
    "                link = results[0]\n",
    "                for source in link[\"sources\"]:\n",
    "                    if source[\"agency_id\"] == \"AU-NUN:DAAO\":\n",
    "                        links.append(\n",
    "                            {\n",
    "                                \"daao_id\": record[\"ori_id\"],\n",
    "                                \"daao_url\": source[\"entity_id\"],\n",
    "                            }\n",
    "                        )\n",
    "    return links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c2e540-df27-4a6b-a705-89f2ebf33aa4",
   "metadata": {
    "tags": [
     "nbval-skip"
    ]
   },
   "outputs": [],
   "source": [
    "# Get the DAAO urls\n",
    "daao_urls = get_daao_urls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9846769-5e4e-418b-98b8-2c631090b74b",
   "metadata": {
    "tags": [
     "nbval-skip"
    ]
   },
   "outputs": [],
   "source": [
    "# Convert the results to a dataframe\n",
    "df_daao = pd.DataFrame(daao_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7881103a-544b-4599-9c63-d12b70c9ef03",
   "metadata": {
    "tags": [
     "nbval-skip"
    ]
   },
   "outputs": [],
   "source": [
    "# Extract the final path segment in the url to use with WD\n",
    "df_daao[\"daao_path\"] = df_daao[\"daao_url\"].str.extract(r\"\\/([^\\/]+)$\")\n",
    "# Save to a file\n",
    "df_daao.to_csv('daao_urls.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "089ab24b367542c98a2c6302587acbe2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "18f3cec8cfce4317a8e39cf2f5bc56b5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "1e6e6b35594a4ce49c812ee9df8ded8a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "3068161cb985448bbdbaf34077bcafd6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "danger",
       "layout": "IPY_MODEL_e34ef3e8bd404df8a838276fa24cd51e",
       "max": 174097,
       "style": "IPY_MODEL_089ab24b367542c98a2c6302587acbe2",
       "value": 172305
      }
     },
     "4e93cf9085434dd0ad3da1c0cd433691": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_1e6e6b35594a4ce49c812ee9df8ded8a",
       "style": "IPY_MODEL_e00677fa8e3047c89088058c150e0b02",
       "value": " 99%"
      }
     },
     "97567eb9fc3e4335813f36da88d830c6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_e1a78359834c4b179265a9180b627186",
       "style": "IPY_MODEL_d5a2794db2a548329914c54f53bdbfb4",
       "value": " 172305/174097 [01:23&lt;00:02, 832.24it/s]"
      }
     },
     "d5a2794db2a548329914c54f53bdbfb4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "e00677fa8e3047c89088058c150e0b02": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "e1a78359834c4b179265a9180b627186": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "e34ef3e8bd404df8a838276fa24cd51e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "e6a895824593479392dbb35b8a7147e0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_4e93cf9085434dd0ad3da1c0cd433691",
        "IPY_MODEL_3068161cb985448bbdbaf34077bcafd6",
        "IPY_MODEL_97567eb9fc3e4335813f36da88d830c6"
       ],
       "layout": "IPY_MODEL_18f3cec8cfce4317a8e39cf2f5bc56b5"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
